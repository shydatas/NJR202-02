# version: "3.9"

x-airflow-common: &airflow-common
    image: shydatas/airflow:latest
    environment:
        # Airflow 核心設定
        AIRFLOW__CORE__EXECUTOR: LocalExecutor
        AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: "true"
        AIRFLOW__CORE__LOAD_EXAMPLES: "false"
        AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
        AIRFLOW__CORE__DEFAULT_TIMEZONE: Asia/Taipei
    env_file:
        - .env
    volumes:
        # 將 airflow.cfg、dags、plugins、logs 掛載到容器中，讓 Airflow 可以使用 airflow.cfg 下的設定
        - ./airflow.cfg:/opt/airflow/airflow.cfg
        - ./dags:/opt/airflow/dags  # 同步 dags 資料夾，讓改動的 dag 可以即時生效
        - ./plugins:/opt/airflow/plugins
        - ./logs:/opt/airflow/logs
        # 將 data_ingestion 和 output 掛載到容器中，讓 Airflow 可以執行 data_ingestion 下的 Python 程式
        - ../data_ingestion:/opt/airflow/data_ingestion
        - ../output:/opt/airflow/output
        # 將 docker.sock 掛載到容器中，讓 Airflow 可以執行 docker 命令
        - /var/run/docker.sock:/var/run/docker.sock
    networks:
        - njr20202_network  # 加入 MySQL 的網路

services:

    postgres:
        image: postgres:13
        container_name: airflow-database
        environment:
            POSTGRES_USER: airflow
            POSTGRES_PASSWORD: airflow
            POSTGRES_DB: airflow
        volumes:
            - postgres-db-volume:/var/lib/postgresql/data
        networks:
            - njr20202_network
    
    airflow-init:
        <<: *airflow-common
        command: >
            bash -c "
            airflow db init &&
            airflow users create --username admin --password admin --firstname Apache --lastname Airflow --role Admin --email admin@example.com
            "
        depends_on:
            - postgres

    airflow-webserver:
        <<: *airflow-common
        command: >
            bash -c "exec airflow webserver"
        container_name: airflow-webserver
        ports: ["8080:8080"]
        healthcheck:
            test: ["CMD-SHELL","curl --fail http://localhost:8080/health || exit 1"]
            interval: 30s
            timeout: 10s
            retries: 5
        depends_on:
            - airflow-init

    airflow-scheduler:
        <<: *airflow-common
        command: >
            bash -c "exec airflow scheduler"
        container_name: airflow-scheduler
        depends_on:
            - airflow-init

volumes:
    postgres-db-volume:

networks:
    njr20202_network:
        external: true